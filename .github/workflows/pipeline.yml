name: Terraform CI/CD

on:
  workflow_dispatch:
  push:
    branches:
      - main
  pull_request:

jobs:
  terraform:
    name: Terraform Plan, Apply, and Destroy
    runs-on: ubuntu-latest

    defaults:
      run:
        working-directory: Infrastructure  # ensure this folder exists in your repo root

    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}
      TF_VERSION: 1.13.1

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Initialize Terraform
        run: terraform init

      - name: Validate Terraform
        run: terraform validate

      - name: Terraform Plan
        run: terraform plan -out=tfplan

      - name: Terraform Apply
        if: github.ref == 'refs/heads/main'
        env:
          TF_VAR_redshift_password: ${{ secrets.AWS_REDSHIFT_PASSWORD }}
        run: terraform apply -auto-approve tfplan

      # Extract the bucket names from Terraform outputs
      - name: Get Bronze bucket name
        id: get_bronze_bucket
        run: |
          BRONZE_BUCKET=$(terraform output -raw bronze_bucket_name)
          echo "bronze_bucket_name=$BRONZE_BUCKET" >> $GITHUB_ENV
          echo "Bronze bucket: $BRONZE_BUCKET"
          SCRIPTS_BUCKET=$(terraform output -raw scripts_bucket_name)
          echo "scripts_bucket_name=$SCRIPTS_BUCKET" >> $GITHUB_ENV
          echo "Scripts bucket: $SCRIPTS_BUCKET"

      # Upload CSV files to S3 Bronze layer
      - name: Upload datasets to S3 Bronze layer
        if: github.ref == 'refs/heads/main'
        run: |
          echo "Uploading CSV files to s3://${{ env.bronze_bucket_name }}/"
          aws s3 cp ../Datasets s3://${{ env.bronze_bucket_name }}/ --recursive --exclude "*" --include "*.csv"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13.7'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('./Scripts/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install pip dependencies
        run: |
          pip install -r ../Scripts/requirements.txt

      - name: Run script
        env:
          BRONZE_BUCKET: ${{ env.bronze_bucket_name }}
        run: python ../Scripts/Bronze/load_bronze_catalog.py

      # Terraform Destroy (manual trigger only)
      - name: Terraform Destroy
        if: github.event_name == 'workflow_dispatch'
        run: terraform destroy -auto-approve